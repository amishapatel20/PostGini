# -*- coding: utf-8 -*-
"""Model_G

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W2kG0OBfPi_UdSaCprLF_DE3WgG7hnlL
"""

import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from transformers import T5Tokenizer, T5ForConditionalGeneration
from diffusers import StableDiffusionPipeline
from PIL import Image, ImageDraw, ImageFont
import os

def load_data(filepath):
    df = pd.read_csv(filepath)
    return train_test_split(df, test_size=0.2, random_state=42)

train_df, test_df = load_data('/content/hotels_festivals_prompts (1).csv')

device = "cuda" if torch.cuda.is_available() else "cpu"
tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small").to(device)

pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
pipe.to(device)

def generate_caption(festival, hotel, prompt):
    input_text = f"Generate a caption for {festival} at {hotel} with theme: {prompt}"
    inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True).to(device)
    output = model.generate(**inputs, max_length=50)
    return tokenizer.decode(output[0], skip_special_tokens=True)

def add_caption(image, caption):
    draw = ImageDraw.Draw(image)
    font = ImageFont.load_default()
    width, height = image.size
    text_width, text_height = draw.textbbox((0, 0), caption, font=font)[2:]
    position = ((width - text_width) // 2, height - text_height - 10)
    draw.text(position, caption, font=font, fill="white")
    return image

output_dir = "/mnt/data/generated_images"
os.makedirs(output_dir, exist_ok=True)

for index, row in test_df.iterrows():
    festival, hotel, prompt = row['Festival Name'], row['Hotel Name'], row['Prompt for DALL-E']

    print(f"Generating image for {festival} at {hotel}...")
    generated_caption = generate_caption(festival, hotel, prompt)
    image = pipe(prompt).images[0]
    image_with_caption = add_caption(image, generated_caption)

    image_path = os.path.join(output_dir, f"{festival}_{hotel}.png")
    image_with_caption.save(image_path)
    print(f"âœ… Image saved: {image_path}")

train_output_dir = "train_images"
os.makedirs(train_output_dir, exist_ok=True)

def generate_image(prompt):
    return pipe(prompt).images[0]

for index, row in train_df.iterrows():
    festival = row['Festival Name']
    hotel = row['Hotel Name']
    prompt = row['Prompt for DALL-E']

    caption = generate_caption(festival, hotel, prompt)















    image = generate_image(prompt)
    image_with_caption = add_caption(image, caption)

    image_path = os.path.join(train_output_dir, f"train_{index}.png")
    image_with_caption.save(image_path)

    print(f" Saved: {image_path}")

test_output_dir = "test_images"
os.makedirs(test_output_dir, exist_ok=True)

for index, row in test_df.iterrows():
    festival = row['Festival Name']
    hotel = row['Hotel Name']
    prompt = row['Prompt for DALL-E']

    caption = generate_caption(festival, hotel, prompt)
    image = generate_image(prompt)
    image_with_caption = add_caption(image, caption)

    image_path = os.path.join(test_output_dir, f"test_{index}.png")
    image_with_caption.save(image_path)

    print(f" Saved: {image_path}")

for true, pred in zip(true_captions, predicted_captions):
    print(f"True: {true}")
    print(f"Predicted: {pred}")
    print(f"Match: {true.lower() == pred.lower()}\n")

from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

smoothing = SmoothingFunction().method1  # Applies slight smoothing
bleu_scores = [sentence_bleu([true.split()], pred.split(), smoothing_function=smoothing)
               for true, pred in zip(true_captions, predicted_captions)]

print(f"Average BLEU Score: {sum(bleu_scores) / len(bleu_scores):.2%}")

!pip install rouge-score

from rouge_score import rouge_scorer

scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)
rouge_scores = [scorer.score(true, pred)['rougeL'].fmeasure for true, pred in zip(true_captions, predicted_captions)]

print(f"Average ROUGE-L Score: {sum(rouge_scores) / len(rouge_scores):.2%}")

from rouge_score import rouge_scorer
import numpy as np

# Ini
scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)

precision_scores, recall_scores, f1_scores = [], [], []

for true, pred in zip(true_captions, predicted_captions):
    scores = scorer.score(true, pred)['rougeL']
    precision_scores.append(scores.precision)
    recall_scores.append(scores.recall)
    f1_scores.append(scores.fmeasure)


accuracy = np.mean(f1_scores) * 100
precision = np.mean(precision_scores) * 100
recall = np.mean(recall_scores) * 100


print(f"Caption Generation Accuracy: {accuracy:.2f}%")
print(f"Precision: {precision:.2f}%")
print(f"Recall: {recall:.2f}%")

model.save_pretrained("model_directory")

from transformers import T5ForConditionalGeneration


model = T5ForConditionalGeneration.from_pretrained("model_directory")